{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from itertools import product\n",
    "\n",
    "# dane\n",
    "from sklearn.datasets import fetch_mldata\n",
    "# splity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# modele\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "# metryki\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "\n",
    "# zawsze przed uczeniem/splitami proszę zrobić shuffle na danych!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 1 [2 pkt]\n",
    "\n",
    "Napisać trzy generatory zestawów hiperparametrów:\n",
    "* generator grid search [robimy wspólnie za 0 pkt],\n",
    "* generator k elementów random grid search,\n",
    "* generator k elementów random search.\n",
    "\n",
    "Hiperparametry podajemy jako słownik {nazwa_hiperparametru: lista_wartości/rozkład}.\n",
    "\n",
    "Generator ma yieldować słowniki {nazwa_hiperparametru: wartość_hiperparametru}\n",
    "\n",
    "Rozkłady prawdopodobieństwa możecie Państwo podawać w dowolny sposób - np. jako pythonową funkcję, jako string z nazwą (a możliwe rozkłady zakodować na sztywno w funkcji zwracającej generatory) itp. Proponuję zastosować konwencję opisaną w następnej komórce [czy ktoś z Państwa ma inny pomysł, jak podawać rozkłady?].\n",
    "\n",
    "Losowe generatory mają przyjmować random_state i działać deterministycznie przy ustalonym random_state (należy ustawić w środku seed generatora liczb losowych na random_state).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tworzymy fabryki samplerów, każda fabryka parametryzuje pewną rodzinę rozkładów prawdopodobieństwa\n",
    "# sampler pamięta jeden konkretny rozkład prawdopodobieństwa\n",
    "# jedynym argumentem samplera jest obiekt numpy.random.RandomState, który oznaczamy rng\n",
    "# sampler zwraca jedną wartość ze swojego rozkładu\n",
    "# ponieważ rng pamięta swój stan, to możemy np. raz stworzyć go na początku i podawać w pętli\n",
    "\n",
    "# rodzina rozkładów jednostajnych na podanych listach elementów\n",
    "# sampler losuje z rozkładu jednostajnego na liście l\n",
    "def uniform_from_list(l):\n",
    "    def sampler(rng):\n",
    "        return l[rng.randint(0,len(l))]\n",
    "    return sampler\n",
    "\n",
    "# rodzina rozkładów jednostajnych na przedziałach liczb całkowitych\n",
    "# sampler losuje z rozkładu jednostajnego na podzbiorze liczb całkowitych od low (włącznie) do high (wyłącznie)\n",
    "def uniform_int_on_interval(low, high):\n",
    "    def sampler(rng):\n",
    "        return rng.randint(low,high)\n",
    "    return sampler\n",
    "\n",
    "# rodzina rozkładów jednostajnych na przedziałach\n",
    "# sampler losuje z rozkładu jednostajnego na przedziale [low, high]\n",
    "def uniform_on_interval(low, high):\n",
    "    def sampler(rng):\n",
    "        return rng.uniform(low, high)\n",
    "    return sampler\n",
    "\n",
    "# rodzina rozkładów jednostajnych na przedziałach w wykładniku potęgi liczby 10\n",
    "# sampler losuje liczbę alpha z rozkładu jednostajnego na przedziale [low, high], a następnie zwraca 10^alpha\n",
    "def log_uniform_on_interval(low, high):\n",
    "    def sampler(rng):\n",
    "        return 10.**rng.uniform(low, high)\n",
    "    return sampler\n",
    "\n",
    "# rodzina rozkładów gaussa\n",
    "# sampler losuje liczbę z rozkładu N(mean, std^2)\n",
    "def normal(mean, std):\n",
    "    def sampler(rng):\n",
    "        return rng.normal(loc=mean, scale=std)\n",
    "    return sampler\n",
    "\n",
    "# rodzina rozkładów gaussa w wykładniku potęgi liczby 10\n",
    "# sampler losuje liczbę alpha z rozkładu N(mean, std^2), a następnie zwraca 10^alpha\n",
    "def log_normal(mean, std):\n",
    "    def sampler(rng):\n",
    "        return 10**rng.normal(loc=mean, scale=std)\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tworzymy obiekt klasy RandomState\n",
      "Losujemy...\n",
      "-0.8425876123531107 0.0004724012431218285 0\n",
      "0.15332290941271645 543.8071598012017 -2\n",
      "-0.34175874759332137 1765.1325190834093 3\n",
      "-0.5937157748565142 8.329228890414763 -1\n",
      "\n",
      "Resetujemy RandomState\n",
      "Losujemy...\n",
      "-0.8425876123531107 0.0004724012431218285 0\n",
      "0.15332290941271645 543.8071598012017 -2\n",
      "-0.34175874759332137 1765.1325190834093 3\n",
      "-0.5937157748565142 8.329228890414763 -1\n",
      "\n",
      "Resetujemy RandomState\n",
      "Losujemy w innej kolejności, wypisujemy w starej...\n",
      "-1.5031075369240603 5.57429041086655 4\n",
      "0.3944672256011211 0.0004724012431218285 0\n",
      "0.34380796428337956 543.8071598012017 0\n",
      "-0.7751061702365221 1765.1325190834093 4\n",
      "\n",
      "samplery współdzielą rng, kolejność losowania ma znaczenie!\n"
     ]
    }
   ],
   "source": [
    "print(\"Tworzymy obiekt klasy RandomState\")\n",
    "rng = RandomState(743)\n",
    "s1 = normal(0.,1.)\n",
    "s2 = log_uniform_on_interval(-4.,4.)\n",
    "s3 = uniform_int_on_interval(-2,5)\n",
    "print(\"Losujemy...\")\n",
    "for _ in range(4):\n",
    "    print(s1(rng), s2(rng), s3(rng))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Resetujemy RandomState\")\n",
    "rng = RandomState(743)\n",
    "s1 = normal(0.,1.)\n",
    "s2 = log_uniform_on_interval(-4.,4.)\n",
    "s3 = uniform_int_on_interval(-2,5)\n",
    "print(\"Losujemy...\")\n",
    "for _ in range(4):\n",
    "    print(s1(rng), s2(rng), s3(rng))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Resetujemy RandomState\")\n",
    "rng = RandomState(743)\n",
    "s1 = normal(0.,1.)\n",
    "s2 = log_uniform_on_interval(-4.,4.)\n",
    "s3 = uniform_int_on_interval(-2,5)\n",
    "print(\"Losujemy w innej kolejności, wypisujemy w starej...\")\n",
    "for _ in range(4):\n",
    "    _s3 = s3(rng)\n",
    "    _s2 = s2(rng)\n",
    "    _s1 = s1(rng)\n",
    "    print(_s1, _s2, _s3)\n",
    "\n",
    "print(\"\")\n",
    "print(\"samplery współdzielą rng, kolejność losowania ma znaczenie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(grid):\n",
    "    (keys, values_grid) = zip(*grid.items())\n",
    "    for values in product(*values_grid):\n",
    "        yield dict(zip(keys, values))\n",
    "\n",
    "def random_grid_search(grid, k=20, random_state=43):\n",
    "    rng = RandomState(random_state) # ustalamy jeden wspólny rng\n",
    "    # wysamplować k zestawów hiperparametrów\n",
    "    (keys, values_grid) = zip(*grid.items())\n",
    "    samplers = []\n",
    "    for i in values_grid:\n",
    "        samplers.append(uniform_from_list(i))\n",
    "    for i in range(k):\n",
    "        samples = []\n",
    "        for sampler in samplers:\n",
    "            samples.append(sampler(rng))\n",
    "        yield dict(zip(keys, samples))\n",
    "\n",
    "def random_search(grid, k=20, random_state=43):\n",
    "    rng = RandomState(random_state) # ustalamy jeden wspólny rng\n",
    "    (keys, samplers) = zip(*sorted(grid.items())) # sortujemy klucze, kolejność samplowania jest ważna!\n",
    "    # wysamplować k zestawów hiperparametrów\n",
    "    for i in range(k):\n",
    "        samples = []\n",
    "        for sampler in samplers:\n",
    "            samples.append(sampler(rng))\n",
    "        yield dict(zip(keys, samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'gamma': 0.0001}\n",
      "{'C': 0.1, 'gamma': 0.0003}\n",
      "{'C': 0.1, 'gamma': 0.001}\n",
      "{'C': 1.0, 'gamma': 0.0001}\n",
      "{'C': 1.0, 'gamma': 0.0003}\n",
      "{'C': 1.0, 'gamma': 0.001}\n",
      "{'C': 10.0, 'gamma': 0.0001}\n",
      "{'C': 10.0, 'gamma': 0.0003}\n",
      "{'C': 10.0, 'gamma': 0.001}\n",
      "{'C': 100.0, 'gamma': 0.0001}\n",
      "{'C': 100.0, 'gamma': 0.0003}\n",
      "{'C': 100.0, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# assert dla grid_search\n",
    "for d in grid_search({'C': [0.1, 1., 10., 100.], 'gamma': [0.0001, 0.0003, 0.001]}):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'C': 0.1, 'gamma': 0.0001}<br/>\n",
    "{'C': 0.1, 'gamma': 0.0003}<br/>\n",
    "{'C': 0.1, 'gamma': 0.001}<br/>\n",
    "{'C': 1.0, 'gamma': 0.0001}<br/>\n",
    "{'C': 1.0, 'gamma': 0.0003}<br/>\n",
    "{'C': 1.0, 'gamma': 0.001}<br/>\n",
    "{'C': 10.0, 'gamma': 0.0001}<br/>\n",
    "{'C': 10.0, 'gamma': 0.0003}<br/>\n",
    "{'C': 10.0, 'gamma': 0.001}<br/>\n",
    "{'C': 100.0, 'gamma': 0.0001}<br/>\n",
    "{'C': 100.0, 'gamma': 0.0003}<br/>\n",
    "{'C': 100.0, 'gamma': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# assert dla random_grid_search\n",
    "# ma wyjść tak samo, jak random_search, tylko z podanymi samplerami uniform_from_list\n",
    "# proszę sobie sprawdzić we własnym zakresie, my uwierzymy na słowo\n",
    "for d in random_grid_search({'C': [0.1, 1., 10., 100.], 'gamma': [0.0001, 0.0003, 0.001]}, k = 1):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.00014143134252521947, 'gamma': 0.06090665392794814, 'nb_sth': 9}\n",
      "{'C': 0.0025462216096392796, 'gamma': 0.03271390558111398, 'nb_sth': 13}\n",
      "{'C': 5.590022241698091e-05, 'gamma': 0.004505286023886656, 'nb_sth': 1}\n",
      "{'C': 1.950465371399982e-05, 'gamma': 0.0733748296280283, 'nb_sth': 13}\n",
      "{'C': 0.0002976304542098269, 'gamma': 0.0011286104130902254, 'nb_sth': 13}\n",
      "{'C': 3.705521747936987e-05, 'gamma': 0.08666486408992002, 'nb_sth': 22}\n",
      "{'C': 31.420766577465653, 'gamma': 0.05808772319264447, 'nb_sth': 22}\n",
      "{'C': 5.842880444285076e-05, 'gamma': 0.08432246942297046, 'nb_sth': 1}\n",
      "{'C': 16.058920736060898, 'gamma': 0.04037700398666926, 'nb_sth': 22}\n",
      "{'C': 35065.59811614318, 'gamma': 0.04457583608397189, 'nb_sth': 22}\n",
      "{'C': 6.683446823678905e-05, 'gamma': 0.08970985799815344, 'nb_sth': 13}\n",
      "{'C': 965.8767858660282, 'gamma': 0.0332329385020804, 'nb_sth': 1}\n",
      "{'C': 0.28068153065434537, 'gamma': 0.08247676837174123, 'nb_sth': 1}\n",
      "{'C': 12207.52376193616, 'gamma': 0.09101530757801567, 'nb_sth': 13}\n",
      "{'C': 0.00015294037493259258, 'gamma': 0.09375550594407336, 'nb_sth': 9}\n"
     ]
    }
   ],
   "source": [
    "for d in random_search(\n",
    "        {'C': log_uniform_on_interval(-5., 5.),\n",
    "         'nb_sth': uniform_from_list([1,4,9,13,22]),\n",
    "         'gamma': uniform_on_interval(0.,0.1)},         \n",
    "        k=15,\n",
    "        random_state=43):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'C': 0.00014143134252521947, 'nb_sth': 9, 'gamma': 0.06090665392794814}<br/>\n",
    "{'C': 0.0025462216096392796, 'nb_sth': 13, 'gamma': 0.03271390558111398}<br/>\n",
    "{'C': 5.590022241698091e-05, 'nb_sth': 1, 'gamma': 0.004505286023886656}<br/>\n",
    "{'C': 1.950465371399982e-05, 'nb_sth': 13, 'gamma': 0.0733748296280283}<br/>\n",
    "{'C': 0.0002976304542098269, 'nb_sth': 13, 'gamma': 0.0011286104130902254}<br/>\n",
    "{'C': 3.705521747936987e-05, 'nb_sth': 22, 'gamma': 0.08666486408992002}<br/>\n",
    "{'C': 31.420766577465653, 'nb_sth': 22, 'gamma': 0.05808772319264447}<br/>\n",
    "{'C': 5.842880444285076e-05, 'nb_sth': 1, 'gamma': 0.08432246942297046}<br/>\n",
    "{'C': 16.058920736060898, 'nb_sth': 22, 'gamma': 0.04037700398666926}<br/>\n",
    "{'C': 35065.59811614318, 'nb_sth': 22, 'gamma': 0.04457583608397189}<br/>\n",
    "{'C': 6.683446823678905e-05, 'nb_sth': 13, 'gamma': 0.08970985799815344}<br/>\n",
    "{'C': 965.8767858660282, 'nb_sth': 1, 'gamma': 0.0332329385020804}<br/>\n",
    "{'C': 0.28068153065434537, 'nb_sth': 1, 'gamma': 0.08247676837174123}<br/>\n",
    "{'C': 12207.52376193616, 'nb_sth': 13, 'gamma': 0.09101530757801567}<br/>\n",
    "{'C': 0.00015294037493259258, 'nb_sth': 9, 'gamma': 0.09375550594407336}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 3 [4 pkt]\n",
    "\n",
    "Zaimplementować algorytm model selection z użyciem podwójnej cross validation (StratifiedKFold w sklearn) zgodnie z opisem w sekcji \"Podsumowanie\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def double_skf_model_evaluation(Model, generator_function, generator_function_kwargs, X, y, metric, selection_n_splits, evaluation_n_splits, random_state):\n",
    "    \"\"\"\n",
    "    Model - klasa modelu\n",
    "    generator_function, generator_function_kwargs - chcemy zrobić coś w stylu:\n",
    "        for hyperparams in generator_function(**generator_function_kwargs):\n",
    "            ...\n",
    "        nie podajemy wprost generatora, bo trzeba go użyć wielokrotnie, a generatorów (chyba?) nie da się kopiować\n",
    "    X,y - dane i etykiety\n",
    "    metric - funkcja o sygnaturze metric(y_true, y_pred), która ocenia skuteczność nauczonego modelu\n",
    "    selection/evaluation_n_splits - liczba splitów/foldów w odpowiednim cross validation\n",
    "    random_state - używany wszędzie tam, gdzie trzeba\n",
    "    \"\"\"\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    # 1. Dzielimy evaluation_n_splits razy (X,y) na (X_train,y_train), (X_test,y_test).\n",
    "    skf = StratifiedKFold(n_splits = evaluation_n_splits, random_state = random_state, shuffle = True)\n",
    "    # 2. Dla każdego takiego podziału:\n",
    "    for i_train, i_test in skf.split(X, y):\n",
    "        X_train = X[i_train] \n",
    "        y_train = y[i_train]\n",
    "        X_test = X[i_test]\n",
    "        y_test = y[i_test]\n",
    "\n",
    "        # 1. Dzielimy selection_n_splits razy (X_train,y_train) na (X_train2,y_train2), (X_valid,y_valid).\n",
    "        skf2 = StratifiedKFold(n_splits = selection_n_splits, random_state = random_state, shuffle = True)\n",
    "            \n",
    "        h_table = []\n",
    "        s_table = []\n",
    "        # 2. Dla każdego zestawu hiperparametrów:\n",
    "        for hyperparams in generator_function(generator_function_kwargs):\n",
    "            # 1. Dla każdego podziału (X_train2,y_train2), (X_valid,y_valid):\n",
    "            h_table.append(hyperparams)\n",
    "            mean_score = 0\n",
    "            for i_train2, i_valid in skf2.split(X_train, y_train):\n",
    "                X_train2 = X[i_train2] \n",
    "                y_train2 = y[i_train2]\n",
    "                X_valid = X[i_valid]\n",
    "                y_valid = y[i_valid]\n",
    "                # 1. Tworzymy model = Model(zestaw_hiperparametrów).\n",
    "                model = Model(**hyperparams)\n",
    "                # 2. Uczymy model na (X_train2,y_train2), testujemy na (X_valid,y_valid) i otrzymujemy score.\n",
    "                model.fit(X_train2, y_train2)\n",
    "                score = metric(y_valid, model.predict(X_valid))\n",
    "                # 3. (zestaw_hiperparametrów, score) zapisujemy w tabelce.\n",
    "                mean_score += score\n",
    "            s_table.append(mean_score)\n",
    "                \n",
    "        # 3. Dla każdego zestawu hiperparametrów mamy trzy różne score z trzech podziałów - uśredniamy je.        \n",
    "        # 4. Wybieramy średnio najlepszy zestaw hiperparametrów.\n",
    "        i = np.argmax(s_table)\n",
    "        final_hyperparams = h_table[i]\n",
    "        # 5. Tworzymy model = Model(średnio_najlepszy_zestaw_hiperparametrów) i uczymy na całym (X_train,y_train).\n",
    "        model = Model(**final_hyperparams)\n",
    "        model.fit(X_train, y_train)\n",
    "        # 6. Testujemy model na (X_test,y_test) i otrzymujemy evaluation_score, zapisujemy go.\n",
    "        scores.append(metric(y_test, model.predict(X_test)))\n",
    "    # 3. Uśredniamy trzy evaluation_score, zwracamy średnią jako ostateczny score Modelu.\n",
    "    final_score = np.mean(scores)\n",
    "    return final_hyperparams, final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 4 [2 pkt]\n",
    "\n",
    "Przy użyciu powyższych funkcji wytrenować porządnie na danych MNIST jeden (dowolnie wybrany) z poniższych modelów:\n",
    "* LinearSVM,\n",
    "* SVM,\n",
    "* RandomForest,\n",
    "* KNN.\n",
    "\n",
    "Zwrócić model i jego estymowany score.\n",
    "\n",
    "[Możemy wspólnie zastanowić się nad sensownym doborem gridów/rozkładów na hiperparametrach.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  {'n_neighbors': 5, 'leaf_size': 20}  score:  0.906665291851\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.RandomState(743).permutation(len(y))\n",
    "_X = X[idx[:3000]]\n",
    "_y = y[idx[:3000]]\n",
    "\n",
    "\n",
    "model, score = double_skf_model_evaluation(\n",
    "    Model = KNeighborsClassifier,\n",
    "    generator_function = grid_search,\n",
    "    generator_function_kwargs = {'n_neighbors': [2,5,8], 'leaf_size': [20,30,40]},\n",
    "    X=_X, y=_y,\n",
    "    metric=accuracy_score,\n",
    "    selection_n_splits=2,\n",
    "    evaluation_n_splits=2,\n",
    "    random_state=43)\n",
    "\n",
    "print(\"Model: \", model, \" score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Model zawsze nauczy się lepiej na większym zbiorze danych. Przez data augmentation rozumiemy cały zbiór technik, które pozwalają \"sztucznie\" niskim kosztem powiększyć dataset. Oczywiście musimy znać etykiety nowowygenerowanych danych. Zazwyczaj działamy w następujący sposób: definiujemy operację, którą możemy zadziałać na pojedynczy $\\mathbf{x}$ bez zmiany odpowiadającego mu $y$, a następnie generujemy z jednego $\\mathbf{x}$ dużo wersji i każdej przypisujemy to samo $y$.\n",
    "\n",
    "Kilka prostych przykładów:\n",
    "* rozpoznawanie mowy ($\\mathbf{x}$ - zapis dźwiękowy, $y$ - tekst wypowiadany przez lektora) - zmieniamy szybkość mówienia, zmieniamy wysokość dźwięku itp.\n",
    "* klasyfikacja obrazków - obracamy obrazki, odbijamy symetrycznie, dodajemy szum, zmieniamy nieco paletę barw itp.\n",
    "\n",
    "Spróbujmy zobaczyć dla przykładu, co się stanie, gdy dodamy gaussowski szum do MNISTa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "idx = np.random.permutation(len(y))\n",
    "X = X[idx[:3000]]\n",
    "y = y[idx[:3000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting KNN (no augmentation)\n",
      "train accuracy: 1.0\n",
      "test accuracy: 0.915151515152\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=43)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "print(\"fitting KNN (no augmentation)\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"train accuracy:\", accuracy_score(y_train, model.predict(X_train)))\n",
    "print(\"test accuracy:\", accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting data...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIvxAUoQfSOp/E8M8Nb//fgoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4258285c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKUrBL1KUgl+kqP8HwNLGgADDDWkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe466fc14e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Augmenting data...\")\n",
    "_X = [X.copy()]\n",
    "_y = [y.copy()]\n",
    "for i in range(7):\n",
    "    _X.append(X.copy() + np.random.normal(scale=3, size=X.shape))\n",
    "    _y.append(y.copy())\n",
    "X_aug = np.vstack(_X)\n",
    "y_aug = np.hstack(_y)\n",
    "\n",
    "plt.imshow(X[-1].reshape(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(X_aug[-1].reshape(28,28), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting KNN (with augmentation)\n",
      "train accuracy: 1.0\n",
      "test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_aug, y_aug, test_size=0.33, random_state=43)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "print(\"fitting KNN (with augmentation)\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"train accuracy:\", accuracy_score(y_train, model.predict(X_train)))\n",
    "print(\"test accuracy:\", accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurra! Po dodaniu stosunkowo prostej augmentacji danych nasz model nauczył się perfekcyjnie generalizować na zbiór testowy! I nie musieliśmy tu stosować żadnej skomplikowanej sieci neuronowej, wystarczył KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 5 (4 pkt)\n",
    "\n",
    "Wytłumaczyć, na czym polega błąd w powyższym rozumowaniu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mistake is that we use train_test_split on the augmented data, so the test set includes data from the training set only with a little noise, and the probability that there will be new, significantly different data in the test set is small. To avoid this, data augmentation should be used only for the training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
